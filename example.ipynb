{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from ModelParallel import ModelParallel, get_device_free_memory\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = [torch.device('cuda:' + str(i)) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [random.random() * 10 for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [math.exp(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X,dtype=torch.float).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(y,dtype=torch.float).unsqueeze(-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIGNLE-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelS(ModelParallel):\n",
    "  def __init__(self):\n",
    "    super(ModelS, self).__init__()\n",
    "    self.layer1 = nn.Linear(1, 10200,bias=False)\n",
    "    self.layer2 = nn.Linear(10200, 10200,bias=False)\n",
    "    self.layer3 = nn.Linear(10200, 10200,bias=False)\n",
    "    self.layer4 = nn.Linear(10200, 10200,bias=False)\n",
    "    self.layer5 = nn.Linear(10200, 10200,bias=False)\n",
    "    self.layer6 = nn.Linear(10200, 10200,bias=False)\n",
    "    self.layerLast = nn.Linear(10200, 1,bias=False)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.layer2(x)\n",
    "    x = self.layer3(x)\n",
    "    x = self.layer4(x)\n",
    "    x = self.layer5(x)\n",
    "    x = self.layer6(x)\n",
    "    x = self.layerLast(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelS(\n",
       "  (layer1): Linear(in_features=1, out_features=10200, bias=False)\n",
       "  (layer2): Linear(in_features=10200, out_features=10200, bias=False)\n",
       "  (layer3): Linear(in_features=10200, out_features=10200, bias=False)\n",
       "  (layer4): Linear(in_features=10200, out_features=10200, bias=False)\n",
       "  (layer5): Linear(in_features=10200, out_features=10200, bias=False)\n",
       "  (layer6): Linear(in_features=10200, out_features=10200, bias=False)\n",
       "  (layerLast): Linear(in_features=10200, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelS()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 9640623616\n",
      "cuda:1 11721506816\n",
      "cuda:2 11721506816\n",
      "cuda:3 11721506816\n"
     ]
    }
   ],
   "source": [
    "for dev in devices:\n",
    "  print(dev, get_device_free_memory(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 - mae 32256041710062.13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1815309909082228"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "nb_batch = 0\n",
    "\n",
    "for epoch in range(1):\n",
    "  mae = 0\n",
    "  nb_batch = 0\n",
    "  for idx in range(0, len(X) - batch_size, batch_size):\n",
    "    features = X[idx:idx+batch_size,:].to(device)\n",
    "    #targets = torch.tensor(y[idx:idx+batch_size],dtype=torch.float).to(device)\n",
    "\n",
    "    pred = model(features)\n",
    "\n",
    "    targets = y[idx:idx+batch_size,:].to(pred.device)\n",
    "\n",
    "    loss = criterion(pred, targets)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    mae += loss.item()\n",
    "    nb_batch += 1\n",
    "\n",
    "  print(\"epoch {} - mae {}\".format(epoch, mae / nb_batch))\n",
    "\n",
    "t2 = time.time()\n",
    "(t2 - t1) / nb_batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTI-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelP(ModelParallel):\n",
    "  def __init__(self):\n",
    "    super(ModelP, self).__init__()\n",
    "    self.layer1 = self.mp_m(nn.Linear(1, 10200,bias=False), 0)\n",
    "    self.layer2 = self.mp_m(nn.Linear(10200, 10200,bias=False), 1)\n",
    "    self.layer3 = self.mp_m(nn.Linear(10200, 10200,bias=False), 0.5)\n",
    "    self.layer4 = self.mp_m(nn.Linear(10200, 10200,bias=False), 0.5)\n",
    "    self.layer5 = self.mp_m(nn.Linear(10200, 10200,bias=False), 1)\n",
    "    self.layer6 = self.mp_m(nn.Linear(10200, 10200,bias=False), 1)\n",
    "    self.layerLast = self.mp_m(nn.Linear(10200, 1,bias=False), 0)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.mp_f(self.layer1, x)\n",
    "    x = self.mp_f(self.layer2, x)\n",
    "    x = self.mp_f(self.layer3, x)\n",
    "    x = self.mp_f(self.layer4, x)\n",
    "    x = self.mp_f(self.layer5, x)\n",
    "    x = self.mp_f(self.layer6, x)\n",
    "    x = self.mp_f(self.layerLast, x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelP()\n",
    "model.to_devices(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 3397971968\n",
      "cuda:1 11305305600\n",
      "cuda:2 10889186304\n",
      "cuda:3 10889145344\n"
     ]
    }
   ],
   "source": [
    "for dev in devices:\n",
    "  print(dev, get_device_free_memory(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 - mae 9300210459076.355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12062265796046104"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "nb_batch = 0\n",
    "\n",
    "for epoch in range(1):\n",
    "  mae = 0\n",
    "  nb_batch = 0\n",
    "  for idx in range(0, len(X) - batch_size, batch_size):\n",
    "    features = X[idx:idx+batch_size,:]\n",
    "    #targets = torch.tensor(y[idx:idx+batch_size],dtype=torch.float).to(device)\n",
    "\n",
    "    pred = model(features)\n",
    "\n",
    "    targets = y[idx:idx+batch_size,:].to(pred.device)\n",
    "\n",
    "    loss = criterion(pred, targets)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    mae += loss.item()\n",
    "    nb_batch += 1\n",
    "\n",
    "  print(\"epoch {} - mae {}\".format(epoch, mae / nb_batch))\n",
    "\n",
    "t2 = time.time()\n",
    "(t2 - t1) / nb_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 7559740416\n",
      "cuda:1 10056700416\n",
      "cuda:2 8392224768\n",
      "cuda:3 8392060928\n"
     ]
    }
   ],
   "source": [
    "for dev in devices:\n",
    "  print(dev, get_device_free_memory(dev))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f810f0bde7d7b5dc90f9e6832822547e13e234c53731a97fc91254323942f40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
