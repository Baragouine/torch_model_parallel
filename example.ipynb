{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from ModelParallel import ModelParallel, get_device_free_memory\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = [torch.device('cuda:' + str(i)) for i in range(3,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [random.random() * 10 for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [math.exp(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X,dtype=torch.float).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(y,dtype=torch.float).unsqueeze(-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIGNLE-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelS(ModelParallel):\n",
    "  def __init__(self):\n",
    "    super(ModelS, self).__init__()\n",
    "    self.layer1 = nn.Linear(1, 102,bias=False)\n",
    "    self.layer2 = nn.Linear(102, 102,bias=False)\n",
    "    self.layer3 = nn.Linear(102, 102,bias=False)\n",
    "    self.layer4 = nn.Linear(102, 102,bias=False)\n",
    "    self.layer5 = nn.Linear(102, 102,bias=False)\n",
    "    self.layer6 = nn.Linear(102, 102,bias=False)\n",
    "    self.layerLast = nn.Linear(102, 1,bias=False)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.layer2(x)\n",
    "    x = self.layer3(x)\n",
    "    x = self.layer4(x)\n",
    "    x = self.layer5(x)\n",
    "    x = self.layer6(x)\n",
    "    x = self.layerLast(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelS(\n",
       "  (layer1): Linear(in_features=1, out_features=102, bias=False)\n",
       "  (layer2): Linear(in_features=102, out_features=102, bias=False)\n",
       "  (layer3): Linear(in_features=102, out_features=102, bias=False)\n",
       "  (layer4): Linear(in_features=102, out_features=102, bias=False)\n",
       "  (layer5): Linear(in_features=102, out_features=102, bias=False)\n",
       "  (layer6): Linear(in_features=102, out_features=102, bias=False)\n",
       "  (layerLast): Linear(in_features=102, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelS()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3 8513898496\n",
      "cuda:4 8514109440\n",
      "cuda:5 8514109440\n"
     ]
    }
   ],
   "source": [
    "for dev in devices:\n",
    "  print(dev, get_device_free_memory(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 - mae 23915952.48387097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.019985483538719914"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "nb_batch = 0\n",
    "\n",
    "for epoch in range(1):\n",
    "  mae = 0\n",
    "  nb_batch = 0\n",
    "  for idx in range(0, len(X) - batch_size, batch_size):\n",
    "    features = X[idx:idx+batch_size,:].to(device)\n",
    "    #targets = torch.tensor(y[idx:idx+batch_size],dtype=torch.float).to(device)\n",
    "\n",
    "    pred = model(features)\n",
    "\n",
    "    targets = y[idx:idx+batch_size,:].to(pred.device)\n",
    "\n",
    "    loss = criterion(pred, targets)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    mae += loss.item()\n",
    "    nb_batch += 1\n",
    "\n",
    "  print(\"epoch {} - mae {}\".format(epoch, mae / nb_batch))\n",
    "\n",
    "t2 = time.time()\n",
    "(t2 - t1) / nb_batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTI-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelP(ModelParallel):\n",
    "  def __init__(self):\n",
    "    super(ModelP, self).__init__()\n",
    "    self.layer1 = self.mp_l(nn.Parameter(torch.empty(1, 102)))\n",
    "    nn.init.xavier_uniform_(self.layer1)\n",
    "    self.layer2 = self.mp_l(nn.Linear(102, 102,bias=False))\n",
    "    self.layer3 = self.mp_l(nn.Linear(102, 102,bias=False))\n",
    "    self.layer4 = self.mp_l(nn.Linear(102, 102,bias=False))\n",
    "    self.layer5 = self.mp_l(nn.Linear(102, 102,bias=False))\n",
    "    self.layer6 = self.mp_l(nn.Linear(102, 102,bias=False))\n",
    "    self.layerLast = self.mp_l(nn.Linear(102, 1,bias=False))\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x.to(self.mp_device(self.layer1))\n",
    "    x = torch.matmul(x, self.layer1)\n",
    "\n",
    "    x = self.mp_f(self.layer2, x)\n",
    "    x = self.mp_f(self.layer3, x)\n",
    "    x = self.mp_f(self.layer4, x)\n",
    "\n",
    "    x = x.to(self.mp_device(self.layer5))\n",
    "    x = self.layer5(x)\n",
    "\n",
    "    x = self.mp_f(self.layer6, x)\n",
    "    x = self.mp_f(self.layerLast, x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelP()\n",
    "model.to_devices(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3 8513221120\n",
      "cuda:4 8514025472\n",
      "cuda:5 8514025472\n"
     ]
    }
   ],
   "source": [
    "for dev in devices:\n",
    "  print(dev, get_device_free_memory(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 - mae 26013714.35483871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02524824296274493"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "nb_batch = 0\n",
    "\n",
    "for epoch in range(1):\n",
    "  mae = 0\n",
    "  nb_batch = 0\n",
    "  for idx in range(0, len(X) - batch_size, batch_size):\n",
    "    features = X[idx:idx+batch_size,:]\n",
    "    #targets = torch.tensor(y[idx:idx+batch_size],dtype=torch.float).to(device)\n",
    "\n",
    "    pred = model(features)\n",
    "\n",
    "    targets = y[idx:idx+batch_size,:].to(pred.device)\n",
    "\n",
    "    loss = criterion(pred, targets)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    mae += loss.item()\n",
    "    nb_batch += 1\n",
    "\n",
    "  print(\"epoch {} - mae {}\".format(epoch, mae / nb_batch))\n",
    "\n",
    "t2 = time.time()\n",
    "(t2 - t1) / nb_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3 8513516032\n",
      "cuda:4 8513773568\n",
      "cuda:5 8513773568\n"
     ]
    }
   ],
   "source": [
    "for dev in devices:\n",
    "  print(dev, get_device_free_memory(dev))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f810f0bde7d7b5dc90f9e6832822547e13e234c53731a97fc91254323942f40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
